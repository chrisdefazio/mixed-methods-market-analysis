{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'python': '3.11.3', 'platform': 'macOS-15.6-arm64-arm-64bit', 'pandas': '2.2.2'}\n"
     ]
    }
   ],
   "source": [
    "# Seed and Versions\n",
    "import sys\n",
    "import platform\n",
    "from importlib.metadata import version\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure project root is on sys.path (handles running from repo root or notebooks/)\n",
    "def _add_project_root_to_sys_path() -> None:\n",
    "    candidates = [Path.cwd(), Path.cwd().parent, Path.cwd().parent.parent]\n",
    "    for base in candidates:\n",
    "        if (base / \"pyproject.toml\").exists() or (base / \"src\").exists():\n",
    "            if str(base) not in sys.path:\n",
    "                sys.path.insert(0, str(base))\n",
    "            return\n",
    "\n",
    "_add_project_root_to_sys_path()\n",
    "\n",
    "from src.utils import set_seed\n",
    "\n",
    "set_seed(42)\n",
    "print({\n",
    "    \"python\": sys.version.split()[0],\n",
    "    \"platform\": platform.platform(),\n",
    "    \"pandas\": version(\"pandas\"),\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Quantitative Analysis\n",
    "\n",
    "Descriptives, ANOVA, OLS regression with HC3, PCA (structured, not executed)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "- Load `data/processed/merged.csv`\n",
    "- Descriptives: summary stats and simple distributions\n",
    "- One-way ANOVA across sectors (and optional by sentiment bin)\n",
    "- OLS: `return ~ sentiment_score + volume + volatility + C(sector)` with HC3 SEs\n",
    "- PCA: standardize features, variance explained, 2D scatter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Data Load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from src.utils import read_csv_safe, validate_columns\n",
    "\n",
    "# Resolve project root so paths are correct when running from notebooks/\n",
    "def _resolve_root() -> Path:\n",
    "    candidates = [Path.cwd(), Path.cwd().parent, Path.cwd().parent.parent]\n",
    "    for base in candidates:\n",
    "        if (base / \"pyproject.toml\").exists() and (base / \"data\").exists():\n",
    "            return base\n",
    "    return Path.cwd()\n",
    "\n",
    "PROJECT_ROOT = _resolve_root()\n",
    "MERGED_PATH = PROJECT_ROOT / \"data/processed/merged.csv\"\n",
    "\n",
    "df = read_csv_safe(MERGED_PATH, parse_dates=[\"date\"]) if MERGED_PATH.exists() else pd.DataFrame()\n",
    "if not df.empty:\n",
    "    validate_columns(df, [\n",
    "        \"date\",\"ticker\",\"sector\",\"close\",\"volume\",\"volatility\",\"return\",\"sentiment_score\",\"n_headlines\"\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N rows: 414\n",
      "Tickers: 6\n",
      "Sectors: 3\n"
     ]
    }
   ],
   "source": [
    "# Print key descriptives for quick reporting\n",
    "if not df.empty:\n",
    "    print(\"N rows:\", len(df))\n",
    "    print(\"Tickers:\", df[\"ticker\"].nunique())\n",
    "    print(\"Sectors:\", df[\"sector\"].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>volatility</th>\n",
       "      <th>return</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>n_headlines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>414.000000</td>\n",
       "      <td>4.140000e+02</td>\n",
       "      <td>414.000000</td>\n",
       "      <td>414.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>99.664377</td>\n",
       "      <td>1.902876e+05</td>\n",
       "      <td>0.306846</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>0.046825</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>33.776359</td>\n",
       "      <td>1.337996e+05</td>\n",
       "      <td>0.055287</td>\n",
       "      <td>0.020344</td>\n",
       "      <td>0.098904</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>44.764300</td>\n",
       "      <td>2.327700e+04</td>\n",
       "      <td>0.041806</td>\n",
       "      <td>-0.051751</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>75.123075</td>\n",
       "      <td>1.060815e+05</td>\n",
       "      <td>0.276396</td>\n",
       "      <td>-0.012992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>94.237050</td>\n",
       "      <td>1.591695e+05</td>\n",
       "      <td>0.305362</td>\n",
       "      <td>0.001818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>129.554225</td>\n",
       "      <td>2.335988e+05</td>\n",
       "      <td>0.343330</td>\n",
       "      <td>0.015848</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>173.885000</td>\n",
       "      <td>1.642350e+06</td>\n",
       "      <td>0.539746</td>\n",
       "      <td>0.067946</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            close        volume  volatility      return  sentiment_score  \\\n",
       "count  414.000000  4.140000e+02  414.000000  414.000000       140.000000   \n",
       "mean    99.664377  1.902876e+05    0.306846    0.001220         0.046825   \n",
       "std     33.776359  1.337996e+05    0.055287    0.020344         0.098904   \n",
       "min     44.764300  2.327700e+04    0.041806   -0.051751        -0.111111   \n",
       "25%     75.123075  1.060815e+05    0.276396   -0.012992         0.000000   \n",
       "50%     94.237050  1.591695e+05    0.305362    0.001818         0.000000   \n",
       "75%    129.554225  2.335988e+05    0.343330    0.015848         0.111111   \n",
       "max    173.885000  1.642350e+06    0.539746    0.067946         0.222222   \n",
       "\n",
       "       n_headlines  \n",
       "count        140.0  \n",
       "mean           1.0  \n",
       "std            0.0  \n",
       "min            1.0  \n",
       "25%            1.0  \n",
       "50%            1.0  \n",
       "75%            1.0  \n",
       "max            1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Basic summary stats and distributions (to be executed later)\n",
    "if not df.empty:\n",
    "    numeric_cols = [\"close\", \"volume\", \"volatility\", \"return\", \"sentiment_score\", \"n_headlines\"]\n",
    "    desc = df[numeric_cols].describe()\n",
    "    display(desc)\n",
    "\n",
    "    # Simple distribution prep (counts per sector)\n",
    "    sector_counts = df[\"sector\"].value_counts().to_frame(name=\"count\").reset_index(names=\"sector\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anova_F': 1.5629731795630133, 'anova_p': 0.21075490953220516}\n"
     ]
    }
   ],
   "source": [
    "# ANOVA across sectors (compute + print)\n",
    "from scipy import stats\n",
    "\n",
    "if not df.empty:\n",
    "    groups = [g[\"return\"].dropna().values for _, g in df.groupby(\"sector\")]\n",
    "    if len(groups) >= 2 and all(len(g) > 1 for g in groups):\n",
    "        res = stats.f_oneway(*groups)\n",
    "        print({\"anova_F\": float(res.statistic), \"anova_p\": float(res.pvalue)})\n",
    "    else:\n",
    "        print(\"ANOVA not computed (insufficient groups)\")\n",
    "else:\n",
    "    print(\"No data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-way ANOVA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coef_sentiment': 0.0043829529421939226, 'p_sentiment': 0.8300988406713853, 'r2': 0.03285253560594781}\n"
     ]
    }
   ],
   "source": [
    "# OLS with HC3: define, fit, and print (safe target name)\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "if not df.empty:\n",
    "    data = df.rename(columns={\"return\": \"ret\"})\n",
    "    data = data.dropna(subset=[\"ret\", \"sentiment_score\", \"volume\", \"volatility\", \"sector\"])\n",
    "    if not data.empty:\n",
    "        model = smf.ols(\n",
    "            formula=\"ret ~ sentiment_score + volume + volatility + C(sector)\",\n",
    "            data=data,\n",
    "        )\n",
    "        ols_results = model.fit(cov_type=\"HC3\")\n",
    "        params = ols_results.params.to_dict()\n",
    "        pvals = ols_results.pvalues.to_dict()\n",
    "        print({\n",
    "            \"coef_sentiment\": float(params.get(\"sentiment_score\", np.nan)),\n",
    "            \"p_sentiment\": float(pvals.get(\"sentiment_score\", np.nan)),\n",
    "            \"r2\": float(ols_results.rsquared),\n",
    "        })\n",
    "    else:\n",
    "        print(\"OLS: no rows after dropna\")\n",
    "else:\n",
    "    print(\"No data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: sentiment bins (for stratified analyses)\n",
    "def bin_sentiment(x: float) -> str:\n",
    "    if x <= -0.2:\n",
    "        return \"neg\"\n",
    "    if x >= 0.2:\n",
    "        return \"pos\"\n",
    "    return \"neu\"\n",
    "\n",
    "if not df.empty and \"sentiment_score\" in df.columns:\n",
    "    df[\"sentiment_bin\"] = df[\"sentiment_score\"].apply(bin_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pca_var_pc1': 0.31230771398881724, 'pca_var_pc2': 0.25425454707082723}\n"
     ]
    }
   ],
   "source": [
    "# PCA variance explained (self-contained)\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "if not df.empty:\n",
    "    feat_cols = [\"return\", \"volume\", \"volatility\", \"sentiment_score\", \"n_headlines\"]\n",
    "    X = df[feat_cols].dropna()\n",
    "    if not X.empty:\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X.values)\n",
    "        pca = PCA(n_components=2)\n",
    "        pca_fit = pca.fit(X_scaled)\n",
    "        explained_var = pca_fit.explained_variance_ratio_\n",
    "        print({\"pca_var_pc1\": float(explained_var[0]), \"pca_var_pc2\": float(explained_var[1])})\n",
    "    else:\n",
    "        print(\"PCA: no rows after dropna\")\n",
    "else:\n",
    "    print(\"No data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS Regression (HC3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell was superseded by the self-contained OLS cell above.\n",
    "# Left intentionally blank to avoid duplicate execution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features and prepare PCA (no execution here)\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pca, scaler, pca_input = None, None, None\n",
    "if not df.empty:\n",
    "    feat_cols = [\"return\", \"volume\", \"volatility\", \"sentiment_score\", \"n_headlines\"]\n",
    "    X = df[feat_cols].dropna()\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X.values)\n",
    "    pca = PCA(n_components=2)\n",
    "    # Do not fit now; structure only\n",
    "    # pca_components = pca.fit_transform(X_scaled)\n",
    "    # explained_var = pca.explained_variance_ratio_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completed\n",
    "\n",
    "Figures and model specifications prepared. See `reports/figures/` after execution.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
