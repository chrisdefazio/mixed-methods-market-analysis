{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'python': '3.11.3', 'platform': 'macOS-15.6-arm64-arm-64bit', 'pandas': '2.2.2'}\n"
          ]
        }
      ],
      "source": [
        "# Seed and Versions\n",
        "import sys\n",
        "import platform\n",
        "from importlib.metadata import version\n",
        "from pathlib import Path\n",
        "\n",
        "# Ensure project root is on sys.path (handles running from repo root or notebooks/)\n",
        "def _add_project_root_to_sys_path() -> None:\n",
        "    candidates = [Path.cwd(), Path.cwd().parent, Path.cwd().parent.parent]\n",
        "    for base in candidates:\n",
        "        if (base / \"pyproject.toml\").exists() or (base / \"src\").exists():\n",
        "            if str(base) not in sys.path:\n",
        "                sys.path.insert(0, str(base))\n",
        "            return\n",
        "\n",
        "_add_project_root_to_sys_path()\n",
        "\n",
        "from src.utils import set_seed\n",
        "\n",
        "set_seed(42)\n",
        "print({\n",
        "    \"python\": sys.version.split()[0],\n",
        "    \"platform\": platform.platform(),\n",
        "    \"pandas\": version(\"pandas\"),\n",
        "})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 03 - Qualitative Analysis\n",
        "\n",
        "Term frequencies, lightweight NMF topic modeling, and a simple hand-coding rubric.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Overview\n",
        "\n",
        "- Load merged dataset\n",
        "- Compute term frequencies with CountVectorizer\n",
        "- NMF topic modeling (k=3–5) and top terms per topic\n",
        "- Optionally join topic intensities by date with avg daily returns\n",
        "- Include a short hand-coding rubric\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports and Data Load\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "from src.utils import read_csv_safe, validate_columns\n",
        "\n",
        "# Resolve project root so paths are correct when running from notebooks/\n",
        "def _resolve_root() -> Path:\n",
        "    candidates = [Path.cwd(), Path.cwd().parent, Path.cwd().parent.parent]\n",
        "    for base in candidates:\n",
        "        if (base / \"pyproject.toml\").exists() and (base / \"data\").exists():\n",
        "            return base\n",
        "    return Path.cwd()\n",
        "\n",
        "PROJECT_ROOT = _resolve_root()\n",
        "MERGED_PATH = PROJECT_ROOT / \"data/processed/merged.csv\"\n",
        "RAW_HEADLINES = PROJECT_ROOT / \"data/raw/headlines.csv\"\n",
        "\n",
        "df = read_csv_safe(MERGED_PATH, parse_dates=[\"date\"]) if MERGED_PATH.exists() else pd.DataFrame()\n",
        "if not df.empty:\n",
        "    validate_columns(df, [\n",
        "        \"date\",\"ticker\",\"sector\",\"close\",\"volume\",\"volatility\",\"return\",\"sentiment_score\",\"n_headlines\"\n",
        "    ])\n",
        "\n",
        "# Build a headlines corpus from raw if needed\n",
        "corpus_df = read_csv_safe(RAW_HEADLINES, parse_dates=[\"date\"]) if RAW_HEADLINES.exists() else pd.DataFrame()\n",
        "if not corpus_df.empty:\n",
        "    validate_columns(corpus_df, [\"date\", \"symbol\", \"headline\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Term Frequencies (CountVectorizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare text corpus\n",
        "texts = corpus_df[\"headline\"].astype(str).tolist() if not corpus_df.empty else []\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = None\n",
        "X_counts = None\n",
        "feature_names = []\n",
        "if texts:\n",
        "    vectorizer = CountVectorizer(lowercase=True, stop_words=\"english\", max_features=5000)\n",
        "    # Structure only; do not fit/transform now\n",
        "    # X_counts = vectorizer.fit_transform(texts)\n",
        "    # feature_names = vectorizer.get_feature_names_out().tolist()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## NMF Topics (k=3–5) and Top Terms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'nmf_components': 4, 'docs': 141, 'top_terms_first_topic': ['misses', 'costs', 'guidance', 'rise', 'nvda', 'amzn', 'msft', 'meta', 'aapl', 'goog']}\n"
          ]
        }
      ],
      "source": [
        "# NMF topics (k=4) and top terms per topic\n",
        "from sklearn.decomposition import NMF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "k = 4\n",
        "W = None\n",
        "H = None\n",
        "terms_by_topic = []\n",
        "feature_names = []\n",
        "\n",
        "texts = corpus_df[\"headline\"].astype(str).tolist() if not corpus_df.empty else []\n",
        "if texts:\n",
        "    tfidf = TfidfVectorizer(lowercase=True, stop_words=\"english\", max_features=5000)\n",
        "    X_tfidf = tfidf.fit_transform(texts)\n",
        "    nmf = NMF(n_components=k, init=\"nndsvda\", random_state=42)\n",
        "    W = nmf.fit_transform(X_tfidf)\n",
        "    H = nmf.components_\n",
        "    feature_names = tfidf.get_feature_names_out().tolist()\n",
        "    topn = 10\n",
        "    for topic_idx, row in enumerate(H):\n",
        "        top_idx = row.argsort()[::-1][:topn]\n",
        "        terms_by_topic.append([feature_names[i] for i in top_idx])\n",
        "    print({\"nmf_components\": k, \"docs\": len(texts), \"top_terms_first_topic\": terms_by_topic[0] if terms_by_topic else []})\n",
        "else:\n",
        "    print(\"No texts available for topic modeling\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Topic Intensities by Date and Avg Daily Returns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'topics_returns_rows': 65, 'saved': '/Users/christopherdefazio/Code/mixed-methods-market-analysis/data/processed/topics_returns.csv'}\n"
          ]
        }
      ],
      "source": [
        "# Topic intensities by date + avg daily returns\n",
        "import pandas as pd\n",
        "\n",
        "topics_returns = pd.DataFrame()\n",
        "if 'W' in globals() and W is not None and not corpus_df.empty:\n",
        "    doc_topics = pd.DataFrame(W).add_prefix(\"topic_\")\n",
        "    doc_topics[\"date\"] = corpus_df[\"date\"].values\n",
        "    daily_topics = doc_topics.groupby(\"date\", as_index=False).mean()\n",
        "    if not df.empty:\n",
        "        daily_returns = (\n",
        "            df.groupby(\"date\", as_index=False)[\"return\"].mean()\n",
        "              .rename(columns={\"return\": \"avg_return\"})\n",
        "        )\n",
        "        topics_returns = daily_topics.merge(daily_returns, on=\"date\", how=\"left\")\n",
        "        out_path = PROJECT_ROOT / \"data/processed/topics_returns.csv\"\n",
        "        out_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        topics_returns.to_csv(out_path, index=False)\n",
        "        print({\"topics_returns_rows\": int(len(topics_returns)), \"saved\": str(out_path)})\n",
        "    else:\n",
        "        print(\"No merged returns available for join\")\n",
        "else:\n",
        "    print(\"No topic weights available for aggregation\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hand-Coding Rubric (Short)\n",
        "\n",
        "- Relevance: Is the headline directly related to firm fundamentals? (0/1)\n",
        "- Sentiment: Negative / Neutral / Positive (choose one)\n",
        "- Actionability: Does the headline suggest an actionable event? (0/1)\n",
        "- Uncertainty: Does the headline introduce uncertainty/ambiguity? (0/1)\n",
        "\n",
        "Annotators should read the full headline context when available and apply consistent criteria across days.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Completed\n",
        "\n",
        "Topic modeling steps prepared. Outputs will be saved after execution.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
