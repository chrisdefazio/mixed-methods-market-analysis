{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01 - Data Preparation\n",
        "\n",
        "This notebook will prepare data (synthetic fallback if we don't have Alpaca keys)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Overview\n",
        "\n",
        "- Set up seed and imports\n",
        "- Load raw CSVs via `src.utils`\n",
        "- Validate required columns and check missingness\n",
        "- Rule-based sentiment on headlines; aggregate by date+symbol\n",
        "- Merge prices, returns, sentiment into clean dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Seed, Imports, and Paths\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from src.utils import set_seed, load_prices, load_returns, load_headlines, validate_columns\n",
        "from src.features import add_sentiment_scores\n",
        "\n",
        "# Reproducibility\n",
        "set_seed(42)\n",
        "\n",
        "# Resolve project root so relative paths work from notebooks/\n",
        "from pathlib import Path as _P\n",
        "\n",
        "_DEF_CANDIDATES = [_P.cwd(), _P.cwd().parent, _P.cwd().parent.parent]\n",
        "for _base in _DEF_CANDIDATES:\n",
        "    if (_base / \"pyproject.toml\").exists() and (_base / \"data\").exists():\n",
        "        PROJECT_ROOT = _base\n",
        "        break\n",
        "else:\n",
        "    PROJECT_ROOT = _P.cwd()\n",
        "\n",
        "DATA_DIR = PROJECT_ROOT / \"data\"\n",
        "RAW_DIR = DATA_DIR / \"raw\"\n",
        "PROCESSED_DIR = DATA_DIR / \"processed\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Dictionary (Schemas)\n",
        "\n",
        "- prices.csv: `date`, `ticker`, `sector`, `close`, `volume`, `volatility`\n",
        "- returns.csv: `date`, `ticker`, `return`\n",
        "- headlines.csv: `date`, `symbol`, `headline`, `source?`, `created_at?`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and Validate Raw Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "prices = load_prices(RAW_DIR / \"prices.csv\")\n",
        "returns = load_returns(RAW_DIR / \"returns.csv\")\n",
        "headlines = load_headlines(RAW_DIR / \"headlines.csv\")\n",
        "\n",
        "# Validate columns explicitly (defensive)\n",
        "validate_columns(prices, [\"date\", \"ticker\", \"sector\", \"close\", \"volume\", \"volatility\"]) if not prices.empty else None\n",
        "validate_columns(returns, [\"date\", \"ticker\", \"return\"]) if not returns.empty else None\n",
        "validate_columns(headlines, [\"date\", \"symbol\", \"headline\"]) if not headlines.empty else None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Missing Data Checks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prices\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "date          0\n",
              "ticker        0\n",
              "sector        0\n",
              "close         0\n",
              "volume        0\n",
              "volatility    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "returns\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "date      0\n",
              "ticker    0\n",
              "return    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "headlines\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "date          0\n",
              "symbol        0\n",
              "headline      0\n",
              "source        0\n",
              "created_at    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def summarize_missing(df, name: str):\n",
        "    if df.empty:\n",
        "        print(f\"{name}: EMPTY\")\n",
        "        return\n",
        "    print(name)\n",
        "    display(df.isna().sum())\n",
        "\n",
        "summarize_missing(prices, \"prices\")\n",
        "summarize_missing(returns, \"returns\")\n",
        "summarize_missing(headlines, \"headlines\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Rule-based Sentiment Scoring and Aggregation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Score sentiment per headline\n",
        "headlines_scored = add_sentiment_scores(headlines) if not headlines.empty else headlines\n",
        "\n",
        "# Aggregate by date + symbol (ticker)\n",
        "if not headlines_scored.empty:\n",
        "    agg = (\n",
        "        headlines_scored\n",
        "        .groupby([\"date\", \"symbol\"], as_index=False)\n",
        "        .agg(sentiment_score=(\"sentiment_score\", \"mean\"),\n",
        "             n_headlines=(\"headline\", \"count\"))\n",
        "    )\n",
        "else:\n",
        "    import pandas as pd\n",
        "    agg = pd.DataFrame(columns=[\"date\", \"symbol\", \"sentiment_score\", \"n_headlines\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Merge Dataset and Save\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Align symbol->ticker for join\n",
        "if not agg.empty:\n",
        "    agg = agg.rename(columns={\"symbol\": \"ticker\"})\n",
        "\n",
        "# Left-join sentiment onto returns then prices for a tidy panel\n",
        "merged = None\n",
        "if not prices.empty and not returns.empty:\n",
        "    pr = prices.merge(returns, on=[\"date\", \"ticker\"], how=\"inner\")\n",
        "    merged = pr.merge(agg, on=[\"date\", \"ticker\"], how=\"left\") if not agg.empty else pr.copy()\n",
        "elif not prices.empty:\n",
        "    merged = prices.copy()\n",
        "elif not returns.empty:\n",
        "    merged = returns.copy()\n",
        "\n",
        "# Write processed output (header-only if empty)\n",
        "from src.utils import write_csv_safe\n",
        "import pandas as pd\n",
        "\n",
        "if merged is None:\n",
        "    merged = pd.DataFrame(columns=[\"date\",\"ticker\",\"sector\",\"close\",\"volume\",\"volatility\",\"return\",\"sentiment_score\",\"n_headlines\"]) \n",
        "\n",
        "write_csv_safe(merged, PROCESSED_DIR / \"merged.csv\", index=False)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
